{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2ceeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from py2neo import Graph\n",
    "from pyhanlp import *\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edfb5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515330c4",
   "metadata": {},
   "source": [
    "为movie.csv,person.csv添加自定义词典"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5a708",
   "metadata": {},
   "source": [
    "  对于带空格的自定义词无法在词库文件中添加，\n",
    "  因为词库文件中一个词条的格式为“word pos   frequency”, \n",
    "  即“词 词性 词频”，\n",
    "  举例：“单身狗 n 1024”，其中是以空格作为分隔符，所以如果自定义词中带空格，会引起格式错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f852ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomDictionary = JClass(\"com.hankcs.hanlp.dictionary.CustomDictionary\")\n",
    "with open(\"./question/movie.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        CustomDictionary.add(line, \"nm 1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10fd02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./question/person.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        CustomDictionary.add(line,\"nr 1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c52199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其实没用到，顺便添加\n",
    "with open(\"./question/rating.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        CustomDictionary.add(line,\"x 1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74c909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其实没用到，顺便添加\n",
    "with open(\"./question/genre.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        CustomDictionary.add(line,\"ng 1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dbe20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为和data/custom中的现代汉语词典中 卧虎藏龙这个成语冲突，所以将txt中nz更改为nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48084c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomDictionary.add(\"卧虎藏龙\", \"nm 1024\")\n",
    "# for term in HanLP.segment(\"卧虎藏龙\"):\n",
    "#     print(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67148356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 强制自定义词典分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52af40c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<java method `enableCustomDictionaryForcing' of 'com.hankcs.hanlp.seg.Segment'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JClass(\"com.hankcs.hanlp.seg.Segment\").enableCustomDictionaryForcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49db247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstractMap = {}\n",
    "vocabulary = {}\n",
    "questions_pattern = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cefba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载词典，构建词典的代码见build_vocab\n",
    "def load_vocabulary():\n",
    "    with open(\"./question/vocabulary.txt\", \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    vocabulary = {}\n",
    "    for line in data:\n",
    "        tokens = line.split(\":\")\n",
    "        index = int(tokens[0])\n",
    "        word = tokens[1].strip()\n",
    "        vocabulary[word] = index\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91dc4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyhanlp分词 得到sentence的独热向量\n",
    "def sentence_to_arrays(sentence):\n",
    "    global vocabulary\n",
    "    # vector是one_hot向量表示，初始化为0，vector是51维 \n",
    "    # vocabulary {'演员': 0,'演': 1,'了': 2,...}\n",
    "    vector = [0] * len(vocabulary.keys())\n",
    "    # pyhanlp分词后结果\n",
    "    for term in HanLP.segment(sentence):\n",
    "        if term.word in vocabulary:\n",
    "            # get得到key值的value(index)序号\n",
    "            index = vocabulary.get(term.word)\n",
    "            vector[index] = 1\n",
    "    # 返回sentence的51维的独热向量vector\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2e49dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_abstract(query_sentence):\n",
    "    \"\"\"将HanLp分词后的关键word，用抽象词性xx替换\n",
    "\n",
    "    :param query_sentence: 查询句子\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 句子抽象化\n",
    "    terms = HanLP.segment(query_sentence)\n",
    "    abstract_query = \"\"\n",
    "    global abstractMap\n",
    "    nr_count = 0\n",
    "    for term in terms:\n",
    "        print(term)\n",
    "        \n",
    "        if \"nm\" in str(term):  # nm 电影名\n",
    "            abstract_query += \"nm \"\n",
    "            abstractMap[\"nm\"] = term.word\n",
    "        elif \"nr\" in str(term) and nr_count == 0:  # nr 人名\n",
    "            abstract_query += \"nr \"\n",
    "            abstractMap[\"nr\"] = term.word\n",
    "            nr_count += 1\n",
    "        elif \"nr\" in str(term) and nr_count == 1:  # nr 人名 再出现一次，改成ntr\n",
    "            abstract_query += \"ntr \"\n",
    "            abstractMap[\"ntr\"] = term.word\n",
    "            nr_count += 1\n",
    "        ### 其实这两个没用到，因为问题模板只有8个。\n",
    "        elif \"x\" in str(term):  # x  评分\n",
    "            abstract_query += \"x \"\n",
    "            abstractMap[\"x\"] = term.word\n",
    "        elif \"ng\" in str(term):  # ng 类型\n",
    "            abstract_query += \"ng \"\n",
    "            abstractMap[\"ng\"] = term.word\n",
    "        else:\n",
    "            abstract_query += term.word + \" \"\n",
    "    print(\"========HanLP分词结束========\")\n",
    "    return abstract_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4aef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 问题分类\n",
    "def query_classify(sentence):\n",
    "    # terms 是51维独热向量。\n",
    "    terms = sentence_to_arrays(sentence)\n",
    "    # 朴素贝叶斯分类\n",
    "    global clf\n",
    "    index = int(clf.predict([terms])[0])\n",
    "    print(\"the model index is \" + str(index))\n",
    "    # 返回对应的问题模板，和model_index\n",
    "    return questions_pattern.get(index), index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09cc0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将sentence还原成问题模板的语句。\n",
    "def sentenceReduction(query_pattern):\n",
    "    \"\"\"\n",
    "    将句子模板还原成正常的语句（分词关键word的抽象词性替换成原有的word）\n",
    "    :param str_pattern:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 替换的模板是每个类的最后一个，当然这个可以更改！\n",
    "    # abstractMap是字典，key是词性,value是单词\n",
    "    global abstractMap\n",
    "    for key in abstractMap.keys():\n",
    "        if key in query_pattern:\n",
    "            value = abstractMap.get(key)\n",
    "            # 将value值替换为抽象map的值\n",
    "            query_pattern = query_pattern.replace(key, value)\n",
    "    \n",
    "#     abstractMap = {}\n",
    "    return query_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37cc4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(query_sentence):\n",
    "    # 原始问句\n",
    "    print(\"原始句子：\" + query_sentence)\n",
    "    print(\"========HanLP开始分词========\")\n",
    "\n",
    "    # 抽象句子，利用HanPL分词，将关键字进行词性抽象\n",
    "    abstract_str = query_abstract(query_sentence)\n",
    "    print(\"句子抽象化结果：\" + abstract_str)\n",
    "\n",
    "    # 将抽象的句子与模板进行匹配，拿到句子对应的模板\n",
    "    str_pattern, model_index = query_classify(abstract_str)\n",
    "    print(\"句子套用模板结果：\" + str_pattern)\n",
    "\n",
    "    # 模板还原成句子，此时问题已转换为我们熟悉的操作\n",
    "    final_pattern = sentenceReduction(str_pattern)\n",
    "    print(\"原始句子替换成系统可识别的结果：\" + final_pattern)\n",
    "\n",
    "    result = [model_index]\n",
    "    result = result + final_pattern.split(\" \")\n",
    "    print(\"==========================\")\n",
    "#     print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7324bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_total=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33892a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=\"question\"):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f_name in files:\n",
    "            # 对于其他文件不识别\n",
    "            if \"【\" in f_name:  # 如：【3】剧情.txt\n",
    "                # e.g. value是数字，代表第几个模板\n",
    "                value = f_name.split(\"】\")[0].replace(\"【\", \"\")\n",
    "                with open(os.path.join(root, f_name)) as f:\n",
    "                    data = f.readlines()\n",
    "                for sentence in data:\n",
    "#                     l=[]\n",
    "                    # 将每一个问题模板(共60个)转化成51维独热向量，append到X中\n",
    "                    # y记录第几个模板\n",
    "#                     terms = HanLP.segment(sentence)\n",
    "#                     for term in terms:\n",
    "#                         l.append(term.word)\n",
    "#                     l_total.append(l)\n",
    "#                     s =\" \".join(l)\n",
    "                    x = sentence_to_arrays(sentence.strip())\n",
    "                    X.append(x)\n",
    "                    Y.append(int(value))\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6a8122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02ef43b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ce54a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open(\"./question/total_question.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c024cc61",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-4a6691590882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# vec=cv.fit_transform(corpus.readlines())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#文本特征值矩阵向量arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/code/envs/miao/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \"\"\"\n\u001b[1;32m   1845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1846\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1847\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/code/envs/miao/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1203\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/code/envs/miao/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/code/envs/miao/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/code/envs/miao/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "vocabulary = load_vocabulary()\n",
    "#cv=TfidfVectorizer(binary=False,decode_error='ignore',stop_words='english')\n",
    "cv=TfidfVectorizer(binary=False,decode_error='ignore')\n",
    "# vec=cv.fit_transform(corpus.readlines())\n",
    "vec=cv.fit_transform(l_total)\n",
    "arr=vec.toarray() #文本特征值矩阵向量arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4211ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af279df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cb88001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_question_templates():\n",
    "    path = \"./question/question_classification.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    questions_pattern = {}\n",
    "    for line in lines:\n",
    "        terms = line.split(\":\")\n",
    "        questions_pattern[int(terms[0])] = terms[1].strip()\n",
    "    # 返回问题模板的字典\n",
    "    return questions_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "052c27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionService(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.g = self.g = Graph(\n",
    "            host=\"localhost\",\n",
    "            http_port=7474,\n",
    "            user=\"neo4j\",\n",
    "            password=\"zzxxxx520\"\n",
    "        )\n",
    "\n",
    "    def answer(self, question) -> str:\n",
    "        # result [4, 'xx这部电影的评分是多少']\n",
    "        result = analysis(question)\n",
    "        answer = None\n",
    "        model_index = result[0]\n",
    "\n",
    "        if model_index == 4:\n",
    "            answer = self.getMovieRating(result)\n",
    "            if answer==\"0\":\n",
    "                answer=\"评分为0，意味着暂无评分哦\"\n",
    "        elif model_index == 6:\n",
    "            answer = self.getMovieReleaseDate(result)\n",
    "        elif model_index == 3:\n",
    "            answer = self.getMovieTypes(result)\n",
    "        elif model_index == 2:\n",
    "            answer = self.getMovieActors(result)\n",
    "        elif model_index == 1:\n",
    "            #  nm 电影作品 == 演员的电影作品有哪些\n",
    "            actorMovies = self.getActorMovies(result)\n",
    "            if actorMovies:\n",
    "                answer = None\n",
    "            else:\n",
    "                answer = actorMovies\n",
    "        elif model_index == 8:\n",
    "            answer = self.getMoviesCount(result)\n",
    "        elif model_index == 5:\n",
    "            answer = self.getActorMoviesType(result)  \n",
    "        elif model_index == 7:\n",
    "            answer = self.getSameMovies(result)   \n",
    "        #         elif model_index == 9:\n",
    "#             # nm 简介 == 电影简介、详情\n",
    "#             title = result[1]\n",
    "#             answer = self.getMovieInfo(title)\n",
    "        #         elif model_index == 5:\n",
    "#             #  nnt 介绍 == 演员简介\n",
    "#             answer = self.getActorInfo(result)\n",
    "#         elif model_index == 8:\n",
    "#             answer = self.getActorMoviesByHScore(result)\n",
    "#         elif model_index == 9:\n",
    "#             answer = self.getActorMoviesByLScore(result)\n",
    "#         elif model_index == 11:\n",
    "#             answer = self.getActorMovies(result)\n",
    "#         elif model_index == 13:\n",
    "#             # nnt  出生日期 == 演员出生日期 * /\n",
    "#             answer = self.getActorBirth(result)\n",
    "#         elif model_index == 5:\n",
    "#             answer = self.getMoviesByType(result)s\n",
    "        global abstractMap\n",
    "        abstractMap = {}\n",
    "        if answer:\n",
    "            return answer\n",
    "        else:\n",
    "            return \"sorry,小可爱,我没有找到你要的答案,换个提问方式试试哦,如果还是没有,可能没有录入这个数据哦\"\n",
    "        \n",
    "    def getActorMovies(self, result):\n",
    "        \"\"\"1对应问题模板1 == nnt(演员) 电影作品\n",
    "\n",
    "        :param name: 演员名\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        global abstractMap\n",
    "        try:\n",
    "            name = abstractMap['nr']\n",
    "        except:\n",
    "            return None\n",
    "        query = f\"match(n:PersonItem)-[:Person2Movie]->(m:MovieItem) where n.name='\"+ name +\"' return m.title\"\n",
    "        answer = self.g.run(query).data()\n",
    "        res=name\n",
    "        res+=\"演过\"\n",
    "        for i in range(len(answer)-1):\n",
    "            res+=answer[i][\"m.title\"]\n",
    "            res+=\"、\"\n",
    "        res+=answer[len(answer)-1][\"m.title\"]\n",
    "        res+=\"。\"\n",
    "        if answer:\n",
    "            return res\n",
    "        return None\n",
    "    def getMovieActors(self, result):\n",
    "        \"\"\"2 对应问题模板2 == nm(电影) 演员\n",
    "\n",
    "        :return: 返回电影的演员有哪些\n",
    "        \"\"\"\n",
    "        global abstractMap\n",
    "        try:\n",
    "            title = abstractMap['nm']\n",
    "        except:\n",
    "            return None\n",
    "        query = f\"match(m:MovieItem)-[:Movie2Person]->(n:PersonItem) where m.title='{title}' return n.name\"\n",
    "        answer = self.g.run(query).data()\n",
    "        res = title\n",
    "        res += \"电影的演员有\"\n",
    "        if answer:\n",
    "            for i in range(len(answer)-1):\n",
    "                res += answer[i].get('n.name')\n",
    "                res += \"、\"\n",
    "            res += answer[len(answer)-1].get('n.name')\n",
    "            res += \"。\"\n",
    "            return res\n",
    "        return None\n",
    "    def getMovieTypes(self,result):\n",
    "        \"\"\"3 对应问题模板3 == nm(电影) 类型\n",
    "\n",
    "        :param result: 电影类型\n",
    "        :return: 返回电影的类型\n",
    "        \"\"\"\n",
    "        global abstractMap\n",
    "        try:\n",
    "            title = abstractMap['nm']\n",
    "        except:\n",
    "            return None\n",
    "        query = f\"match(m:MovieItem)-[Movie2Genre]->(n:GenreItem) where m.title='{title}' return n.gname\"\n",
    "        answer = self.g.run(query).data()\n",
    "        if answer:\n",
    "            return answer[0].get('n.gname')\n",
    "        return None\n",
    "    def getMovieRating(self, result):\n",
    "        \"\"\"4 对应问题模板4 == nm(电影) 评分\n",
    "\n",
    "        :param result: 电影标题\n",
    "        :return: 返回电影的评分\n",
    "        \"\"\"\n",
    "        # **nm 评分 == 电影评分*/\n",
    "        global abstractMap\n",
    "        try:\n",
    "            title = abstractMap['nm']\n",
    "        except:\n",
    "            return None\n",
    "        query = f\"match(n:MovieItem) where n.title='{title}' return n.rating\"\n",
    "        answer = self.g.run(query).data()\n",
    "        if answer:\n",
    "            return answer[0].get('n.rating')\n",
    "        return None    \n",
    "    def getActorMoviesType(self, result):\n",
    "        \"\"\"5 对应问题模板5 == nr(演员) 电影类型\n",
    "\n",
    "        :param result: 电影标题\n",
    "        :return: 返回电影的评分\n",
    "        \"\"\"\n",
    "        global abstractMap\n",
    "        try:\n",
    "            name = abstractMap['nr']\n",
    "        except:\n",
    "            return None\n",
    "#         tmp_mv=\"\" 不会被后面替换\n",
    "        query = f\"match(n:PersonItem)-[:Person2Movie]->(m:MovieItem) where n.name='{name}' return m.title\"\n",
    "        answer = self.g.run(query).data()\n",
    "        res = name\n",
    "        res += \"演过\"\n",
    "        l = []\n",
    "        if answer:\n",
    "            for i in range(len(answer)-1):\n",
    "                tmp_mv = answer[i].get('m.title')\n",
    "                query2 = f\"match(m:MovieItem)-[:Movie2Genre]->(n:GenreItem) where m.title=\\\"\"+tmp_mv+\"\\\" return n.gname\"\n",
    "                tmp_res = self.g.run(query2).data()\n",
    "                if tmp_res:\n",
    "                    tmp_res = tmp_res[0].get('n.gname')\n",
    "                if tmp_res and tmp_res not in l:\n",
    "                    l.append(tmp_res)\n",
    "                    res += tmp_res\n",
    "                    res += \"、\"\n",
    "            tmp_mv = answer[len(answer)-1].get('m.title')\n",
    "            tmp_res = self.g.run(query2).data()\n",
    "            if tmp_res:\n",
    "                tmp_res = tmp_res[0].get('n.gname')\n",
    "            if tmp_res and tmp_res not in l:\n",
    "                l.append(tmp_res)\n",
    "                res+= tmp_res\n",
    "            res+=\"类型的电影。\"\n",
    "            return res\n",
    "        return None\n",
    "    def getMovieReleaseDate(self, result):\n",
    "        \"\"\"6 对应问题模板6 == nm(电影) 上映时间\n",
    "\n",
    "        :param result: 电影标题\n",
    "        :return: 返回电影的评分\n",
    "        \"\"\"\n",
    "        global abstractMap\n",
    "        try:\n",
    "            title = abstractMap['nm']\n",
    "        except:\n",
    "            return None\n",
    "        query = f\"match(m:MovieItem) where m.title=\\\"\"+title+\"\\\" return m.releasedate\"\n",
    "        answer = self.g.run(query).data()\n",
    "        if answer:\n",
    "            return answer[0].get('m.releasedate')\n",
    "        return None\n",
    "    def getSameMovies(self, result):\n",
    "        \"\"\"7 对应问题模板7 == nr(a演员) ntr(b演员) 合作工作\n",
    "\n",
    "        :return: 返回合作工作\n",
    "        \"\"\"\n",
    "        global abstractMap\n",
    "        try:\n",
    "            nr = abstractMap['nr']\n",
    "            ntr = abstractMap['ntr']\n",
    "        except:\n",
    "            return None\n",
    "        query = f\"match(n:PersonItem)-[Person2Movie]->(m:MovieItem) where n.name='{nr}' return m.title\"\n",
    "        query2 = f\"match(n:PersonItem)-[Person2Movie]->(m:MovieItem) where n.name='{ntr}' return m.title\"\n",
    "        answer1 = self.g.run(query).data()\n",
    "        answer2 = self.g.run(query2).data()\n",
    "        if answer1 and answer2:\n",
    "            # 两个list取交集\n",
    "            intersection_d = [val for val in answer1 if val in answer2]\n",
    "            if intersection_d:\n",
    "                res = nr\n",
    "                res += \"和\"\n",
    "                res += ntr\n",
    "                res += \"合作了\"\n",
    "                for i in range(len(intersection_d)-1):\n",
    "                    res += intersection_d[i].get('m.title')\n",
    "                    res +='、'\n",
    "                res += intersection_d[len(intersection_d)-1].get('m.title')\n",
    "                res +=\"。\"\n",
    "            else:\n",
    "                res = nr+\"和\"+ntr+\"没合作过电影作品。\"\n",
    "            return res\n",
    "        return None\n",
    "    def getMoviesCount(self, result):\n",
    "        \"\"\"8 对应问题模板8 == nr(演员) 出演过多少部电影\n",
    "\n",
    "        :return: 出演过多少部电影\n",
    "        \"\"\"\n",
    "        global abstractMap\n",
    "        try:\n",
    "            nr = abstractMap['nr']\n",
    "        except:\n",
    "            return None\n",
    "        query = f\"match(n:PersonItem)-[:Person2Movie]->(m:MovieItem) where n.name='{nr}' return m.title\"\n",
    "        answer = self.g.run(query).data()\n",
    "        if answer:\n",
    "            res = nr+\"出演过\"+ str(len(answer)) +\"部电影。\"\n",
    "            return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "776d356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = load_vocabulary()\n",
    "#cv=TfidfVectorizer(binary=False,decode_error='ignore',stopwords='english')\n",
    "cv=TfidfVectorizer(binary=False,decode_error='ignore')\n",
    "vec=cv.fit_transform(vocabulary)\n",
    "arr=vec.toarray() #文本特征值矩阵向量arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3edb9823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(decode_error='ignore')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49268a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bae1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(list(map(lambda x: dicts[x.strip()], corpus_tags))) #标签矩阵向量a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66025c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始句子：Yat luk che 电影的上映时间是什么时候\n",
      "========HanLP开始分词========\n",
      "Yat luk che/nm\n",
      " /w\n",
      "电影/n\n",
      "的/ude1\n",
      "上映/v\n",
      "时间/n\n",
      "是/vshi\n",
      "什么/ry\n",
      "时候/n\n",
      "========HanLP分词结束========\n",
      "句子抽象化结果：nm   电影 的 上映 时间 是 什么 时候 \n",
      "the model index is 6\n",
      "句子套用模板结果：nm 什么时候首播\n",
      "原始句子替换成系统可识别的结果：Yat luk che 什么时候首播\n",
      "==========================\n",
      "2002/9/19\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    questions_pattern = load_question_templates()\n",
    "    vocabulary = load_vocabulary()\n",
    "    \n",
    "    X, Y = load_data()\n",
    "    # 朴素贝叶斯\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X, Y)\n",
    "\n",
    "    question_service = QuestionService()\n",
    "    # 模板1的测试\n",
    "#     print(question_service.answer('周星驰有什么作品'))\n",
    "#     print(question_service.answer('Chen Dao-Ming 有什么作品'))\n",
    "    # 模板2的测试\n",
    "#     print(question_service.answer(\"Yat luk che有哪些人出演\"))\n",
    "    # 模板3的测试\n",
    "#     print(question_service.answer(\"Yat luk che是什么类型的电影\"))\n",
    "#     print(question_service.answer(\"英雄是什么风格的电影\"))\n",
    "    # 模板4的测试\n",
    "#     print(question_service.answer('Yat luk che这部电影的评分是多少'))\n",
    "    # 模板5的测试\n",
    "#     print(question_service.answer('李连杰演过哪些类型的电影'))\n",
    "    # 模板6的测试\n",
    "    print(question_service.answer('Yat luk che 电影的上映时间是什么时候'))\n",
    "    # 模板7的测试\n",
    "#     print(question_service.answer('章子怡和李连杰合作过哪些电影'))\n",
    "    # 模板8的测试\n",
    "#     print(question_service.answer('章子怡出演过多少部电影'))\n",
    "#     abstractMap = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16103bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_service = QuestionService()\n",
    "\n",
    "\n",
    "answer = question_service.g.run(\"MATCH (n:MovieItem{title:\\\"英雄\\\"})-[rel:Movie2Person]-(entity2)  RETURN n.title,rel.type,entity2.name\").data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "833545ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "63c582cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n.title': '英雄', 'rel.type': '演员', 'entity2.name': '梁朝伟'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e32b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9723435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 朴素贝叶斯\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a037cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_service = QuestionService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbeb60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = [{\"entity1\": {\"rating\": \"7.199999809\", \"mid\": \"146\", \"releasedate\": \"2000/10/1\", \"title\": \"卧虎藏龙\", \"introduction\": \"一代大侠李慕白有退出江湖之意，托付红颜知己俞秀莲将自己的青冥剑带到京城，作为礼物送给贝勒爷收藏。这把有四百年历史的古剑伤人无数，李慕白希望如此重大决断能够表明他离开江湖恩怨的决心。谁知当天夜里宝剑就被人盗走，俞秀莲上前阻拦与盗剑人交手，但最后盗剑人在同伙的救助下逃走。有人看见一个蒙面人消失在九门提督玉大人府内，俞秀莲也认为玉大人难逃干系。九门提督主管京城治安，玉大人刚从新疆调来赴任，贝勒爷即不相信玉大人与此有关，也不能轻举妄动以免影响大局。 　　俞秀莲为了不将事情复杂化一直在暗中查访宝剑下落，也大约猜出是玉府小姐玉蛟龙一时意气所为。俞秀莲对前来京城的李慕白隐瞒消息，只想用旁敲侧击的方法迫使玉蛟龙归还宝剑，免伤和气。不过俞秀莲的良苦用心落空，蒙面人真的归还宝剑时，不可避免地跟李慕白有了一次正面的交锋。而李慕白又发现了害死师傅的碧眼狐狸的踪迹，此时李慕白更是欲罢不能。 　　玉蛟龙自幼被隐匿于玉府的碧眼狐狸暗中收为弟子，并从秘籍中习得武当派上乘武功，早已青出于蓝。在新疆之时，玉蛟龙就瞒着父亲与当地大盗“半天云”罗小虎情定终身，如今身在北京，父亲又要她嫁人，玉蛟龙一时兴起冲出家门浪迹江湖。 　　任性傲气的玉蛟龙心中凄苦无处发泄，在江湖上使性任气，俨然是个小魔星。俞秀莲和李慕白爱惜玉蛟龙人才难得，苦心引导，总是无效。在最后和碧眼狐狸的交手之中，李慕白为救玉蛟龙身中毒针而死。玉蛟龙在俞秀莲的指点下来到武当山，却无法面对罗小虎，在和罗小虎一夕缠绵之后，投身万丈绝壑。\"}, \"rel\": {\"type\": \"演员\"}, \"entity2\": {\"birthplace\": \"Shanghai, China\", \"name\": \"Cheng Pei-Pei\", \"birth\": \"1946/12/4\", \"pid\": \"1624\"}, \"\": \"\"}, {\"entity1\": {\"rating\": \"7.199999809\", \"mid\": \"146\", \"releasedate\": \"2000/10/1\", \"title\": \"卧虎藏龙\", \"introduction\": \"一代大侠李慕白有退出江湖之意，托付红颜知己俞秀莲将自己的青冥剑带到京城，作为礼物送给贝勒爷收藏。这把有四百年历史的古剑伤人无数，李慕白希望如此重大决断能够表明他离开江湖恩怨的决心。谁知当天夜里宝剑就被人盗走，俞秀莲上前阻拦与盗剑人交手，但最后盗剑人在同伙的救助下逃走。有人看见一个蒙面人消失在九门提督玉大人府内，俞秀莲也认为玉大人难逃干系。九门提督主管京城治安，玉大人刚从新疆调来赴任，贝勒爷即不相信玉大人与此有关，也不能轻举妄动以免影响大局。 　　俞秀莲为了不将事情复杂化一直在暗中查访宝剑下落，也大约猜出是玉府小姐玉蛟龙一时意气所为。俞秀莲对前来京城的李慕白隐瞒消息，只想用旁敲侧击的方法迫使玉蛟龙归还宝剑，免伤和气。不过俞秀莲的良苦用心落空，蒙面人真的归还宝剑时，不可避免地跟李慕白有了一次正面的交锋。而李慕白又发现了害死师傅的碧眼狐狸的踪迹，此时李慕白更是欲罢不能。 　　玉蛟龙自幼被隐匿于玉府的碧眼狐狸暗中收为弟子，并从秘籍中习得武当派上乘武功，早已青出于蓝。在新疆之时，玉蛟龙就瞒着父亲与当地大盗“半天云”罗小虎情定终身，如今身在北京，父亲又要她嫁人，玉蛟龙一时兴起冲出家门浪迹江湖。 　　任性傲气的玉蛟龙心中凄苦无处发泄，在江湖上使性任气，俨然是个小魔星。俞秀莲和李慕白爱惜玉蛟龙人才难得，苦心引导，总是无效。在最后和碧眼狐狸的交手之中，李慕白为救玉蛟龙身中毒针而死。玉蛟龙在俞秀莲的指点下来到武当山，却无法面对罗小虎，在和罗小虎一夕缠绵之后，投身万丈绝壑。\"}, \"rel\": {\"type\": \"演员\"}, \"entity2\": {\"birthplace\": \"Lamma Island, Hong Kong\", \"name\": \"周润发\", \"birth\": \"1955/5/18\", \"pid\": \"1619\", \"biography\": \"周润发，广东宝安人，1955年5月18日生于香港南丫岛，为新界原居民，著名电影和电视演员，曾经三度获得香港电影金像奖最佳男主角奖，另外也拿到两次台湾电影金马奖最佳男主角头衔。 1980年代与成龙一并成为香港电影市场的票房保证，并创造了多个脍炙人口的经典角色：许文强、小马哥、赌神等多不胜数。1990年代开始后，与成龙、周星驰因为电影票房成绩出色，共同被媒体形容为“双周一成”。他于1995年赴美国好莱坞发展，在拍摄多部电影后获得一定程度上的成功。\"}, \"\": \"\"}, {\"entity1\": {\"rating\": \"7.199999809\", \"mid\": \"146\", \"releasedate\": \"2000/10/1\", \"title\": \"卧虎藏龙\", \"introduction\": \"一代大侠李慕白有退出江湖之意，托付红颜知己俞秀莲将自己的青冥剑带到京城，作为礼物送给贝勒爷收藏。这把有四百年历史的古剑伤人无数，李慕白希望如此重大决断能够表明他离开江湖恩怨的决心。谁知当天夜里宝剑就被人盗走，俞秀莲上前阻拦与盗剑人交手，但最后盗剑人在同伙的救助下逃走。有人看见一个蒙面人消失在九门提督玉大人府内，俞秀莲也认为玉大人难逃干系。九门提督主管京城治安，玉大人刚从新疆调来赴任，贝勒爷即不相信玉大人与此有关，也不能轻举妄动以免影响大局。 　　俞秀莲为了不将事情复杂化一直在暗中查访宝剑下落，也大约猜出是玉府小姐玉蛟龙一时意气所为。俞秀莲对前来京城的李慕白隐瞒消息，只想用旁敲侧击的方法迫使玉蛟龙归还宝剑，免伤和气。不过俞秀莲的良苦用心落空，蒙面人真的归还宝剑时，不可避免地跟李慕白有了一次正面的交锋。而李慕白又发现了害死师傅的碧眼狐狸的踪迹，此时李慕白更是欲罢不能。 　　玉蛟龙自幼被隐匿于玉府的碧眼狐狸暗中收为弟子，并从秘籍中习得武当派上乘武功，早已青出于蓝。在新疆之时，玉蛟龙就瞒着父亲与当地大盗“半天云”罗小虎情定终身，如今身在北京，父亲又要她嫁人，玉蛟龙一时兴起冲出家门浪迹江湖。 　　任性傲气的玉蛟龙心中凄苦无处发泄，在江湖上使性任气，俨然是个小魔星。俞秀莲和李慕白爱惜玉蛟龙人才难得，苦心引导，总是无效。在最后和碧眼狐狸的交手之中，李慕白为救玉蛟龙身中毒针而死。玉蛟龙在俞秀莲的指点下来到武当山，却无法面对罗小虎，在和罗小虎一夕缠绵之后，投身万丈绝壑。\"}, \"rel\": {\"type\": \"演员\"}, \"entity2\": {\"birthplace\": \"Beijing , China\", \"name\": \"章子怡\", \"birth\": \"1979/2/9\", \"pid\": \"1339\"}, \"\": \"\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityRelationbyEntity(self, value):\n",
    "\n",
    "    answer = self.graph.run(\"MATCH (entity1) - [rel] -> (entity2)  WHERE entity1.name = \\\"\" + str(\n",
    "                value) + \"\\\" RETURN entity1,rel,entity2\").data()\n",
    "    ##  要用if not answer , 而不是判断是不是none，因为没有答案就是【】\n",
    "    if not answer:\n",
    "        # 关系查询中，如果是movie的查询，只返回电影的演员\n",
    "        answer = self.graph.run(\"MATCH (entity1) - [rel:Movie2Person] -> (entity2)  WHERE entity1.title = \\\"\" + str(\n",
    "            value) + \"\\\" RETURN entity1,rel,entity2\").data()\n",
    "    if not answer:\n",
    "        answer = self.graph.run(\"MATCH (entity1) - [rel] -> (entity2)  WHERE entity1.gname = \\\"\" + str(\n",
    "            value) + \"\\\" RETURN entity1,rel,entity2\").data()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b51c8275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'birthplace': 'Shanghai, China',\n",
       " 'name': 'Cheng Pei-Pei',\n",
       " 'birth': '1946/12/4',\n",
       " 'pid': '1624'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt[0][\"entity2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53bfa3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"title\" in lt[0][\"entity2\"]:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb46972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miao",
   "language": "python",
   "name": "miao"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
